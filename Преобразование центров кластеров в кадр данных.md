После обучения кластеризатора будут доступны центры кластеров
```scala
bisectKmeansModel.stages(2).asInstanceOf[BisectingKMeansModel].clusterCenters
```

Однако они представлены массивом векторов. Чтобы преобразовать этот массив векторов в кадр данных, можно сделать так
```scala
import org.apache.spark.sql.DataFrame

def convertBisectKmeansCenterClustersToDataFrame(
  model: PipelineModel,
): DataFrame = {
  import spark.implicits._  // NB!!! Позволяет создавать кадры данных на базе вальных структур Scala

  val featureNames: Array[String] =
    model.stages(0).asInstanceOf[VectorAssembler].getInputCols

  model.stages(2).asInstanceOf[BisectingKMeansModel].clusterCenters
    .map(center => center.toArray.toList).toList.toDF
    .select(
      List.range(0, featureNames.length).map(
        colIdx => col("value").getItem(colIdx).alias(featureNames(colIdx))
      ): _*
    )
}
```

Восстановить оригинальный масштаб признаков после `StandardScaler` можно так
```scala
import org.apache.spark.sql.functions._

private def getCenterClusters(pipeline: PipelineModel): DataFrame = {
  import spark.implicits._

  val featureNames: Array[String] = 
    pipeline.stages(0).asInstanceOf[VectorAssembler].getInputCols

    pipeline.stages(2).asInstanceOf[BisectKMeansModel].clusterCenters
      .map(center => center.toArray.toList).toList.toDF()
      .select(
        List.range(0, featureNames.length).map(
          featureIdx => 
            col("value").getItem(featureIdx).alias(featureNames(featureIdx))
        ): _*
      )
}

def getAggregate
(
  input: DataFrame,
  aggName: String,
): DataFrame = {
  input.select(
    input.columns.map(
      c => call_udf(aggName, col(c))
    ): _*
  )
}

private def convertDataFrameToMap(input: DataFrame): Map[String, Double] = {
  input.collect()
    .map(row => Map(
      input.columns.zip(row.toSeq.map(_.toString.toDouble)): _*
    ))
    .toList.head
}

val centerClusters = getCenterClusters(pipeline)

val avgSummary = getAggregate(input, Constants.aggNameAvg)
val stddevSummary = getAggregate(input, Constants.aggNameStddev)

val avgs = convertDataFrameToMap(avgSummary)
val stddevs = convertDataFrameToMap(stddevSummary)

// foldLeft !!!
centerClusters.columns.foldLeft(centerClusters) {
  (tempDf, colName) => 
    tempDf.withColumn(
      colName,
      (col(colName) * lit(stddevs(colName))) + lit(avgs(colName))
    )
}
```